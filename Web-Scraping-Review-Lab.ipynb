{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Web Scraping Lab**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **30** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing this lab, you will be able to:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Download a webpage using requests module\n",
    "* Scrape all links from a webpage\n",
    "* Scrape all image URLs from a web page\n",
    "* Scrape data from html tables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape www.ibm.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required modules and functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # this module helps in web scrapping.\n",
    "import requests  # this module helps us to download a webpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the contents of the webpage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.ibm.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the contents of the webpage in text format and store in a variable called data\n",
    "data  = requests.get(url).text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a soup object using the class BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(data,\"html.parser\")  # create a soup object using the variable 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape all links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.ibm.com/products/guardium-ai-security?lnk=hpls1us\n",
      "https://newsroom.ibm.com/2025-06-18-ibm-introduces-industry-first-software-to-unify-agentic-governance-and-security?lnk=hpls2us\n",
      "https://www.ibm.com/granite?lnk=hpdev1us\n",
      "https://ibmtechxchange.bemyapp.com/#/event?lnk=hpdev2us\n",
      "https://skillsbuild.org/?lnk=hpdev3us\n",
      "https://www.ibm.com/new/announcements/agentic-ai-governance-evaluation-and-lifecycle?lnk=hpdev4us\n",
      "https://www.ibm.com/new/announcements/ibm-named-a-leader-in-the-2025-gartner-magic-quadrant-for-data-science-and-machine-learning-platforms?lnk=hpdev5us\n",
      "https://www.ibm.com/new/announcements/ibm-leader-2025-omdia-universe-on-no-low-pro-ide-assistants-report?lnk=hpdev6us\n",
      "https://www.ibm.com/products/watsonx-code-assistant/pricing?lnk=hpdev7us\n",
      "https://www.ibm.com/products/watsonx-ai?lnk=hpdev8us\n",
      "https://www.ibm.com/products/spss-statistics/whats-new?lnk=hppr1us\n",
      "https://www.ibm.com/artificial-intelligence?lnk=hpfp1us\n",
      "https://www.ibm.com/solutions/hybrid-cloud\n",
      "https://www.ibm.com/consulting?lnk=hpfp3us\n",
      "https://www.ibm.com/about?lnk=hpii1us\n",
      "https://www.ibm.com/history?lnk=hpii1us\n",
      "https://research.ibm.com?lnk=hpii1us\n",
      "https://www.ibm.com/quantum?lnk=hpii1us\n",
      "https://www.ibm.com/careers?lnk=hpii1us\n",
      "https://skillsbuild.org?lnk=hpii1us\n"
     ]
    }
   ],
   "source": [
    "for link in soup.find_all('a'):  # in html anchor/link is represented by the tag <a>\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape  all images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in soup.find_all('img'):# in html image is represented by the tag <img>\n",
    "    print(link.get('src'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape data from html tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The below URL contains a html table with data about colors and color codes.\n",
    "URL = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/HTMLColorCodes.html\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding to scrape a website, you need to examine the contents, and the way data is organized on the website. Open the above URL in your browser and check how many rows and columns are there in the color table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the contents of the webpage in text format and store in a variable called data\n",
    "data  = requests.get(URL).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(data,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find a html table in the web page\n",
    "table = soup.find('table') # in html table is represented by the tag <table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all rows from the table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color Name--->Hex Code#RRGGBB\n",
      "lightsalmon--->#FFA07A\n",
      "salmon--->#FA8072\n",
      "darksalmon--->#E9967A\n",
      "lightcoral--->#F08080\n",
      "coral--->#FF7F50\n",
      "tomato--->#FF6347\n",
      "orangered--->#FF4500\n",
      "gold--->#FFD700\n",
      "orange--->#FFA500\n",
      "darkorange--->#FF8C00\n",
      "lightyellow--->#FFFFE0\n",
      "lemonchiffon--->#FFFACD\n",
      "papayawhip--->#FFEFD5\n",
      "moccasin--->#FFE4B5\n",
      "peachpuff--->#FFDAB9\n",
      "palegoldenrod--->#EEE8AA\n",
      "khaki--->#F0E68C\n",
      "darkkhaki--->#BDB76B\n",
      "yellow--->#FFFF00\n",
      "lawngreen--->#7CFC00\n",
      "chartreuse--->#7FFF00\n",
      "limegreen--->#32CD32\n",
      "lime--->#00FF00\n",
      "forestgreen--->#228B22\n",
      "green--->#008000\n",
      "powderblue--->#B0E0E6\n",
      "lightblue--->#ADD8E6\n",
      "lightskyblue--->#87CEFA\n",
      "skyblue--->#87CEEB\n",
      "deepskyblue--->#00BFFF\n",
      "lightsteelblue--->#B0C4DE\n",
      "dodgerblue--->#1E90FF\n"
     ]
    }
   ],
   "source": [
    "for row in table.find_all('tr'): # in html table row is represented by the tag <tr>\n",
    "    # Get all columns in each row.\n",
    "    cols = row.find_all('td') # in html a column is represented by the tag <td>\n",
    "    color_name = cols[2].getText() # store the value in column 3 as color_name\n",
    "    color_code = cols[3].getText() # store the value in column 4 as color_code\n",
    "    print(\"{}--->{}\".format(color_name,color_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Color Name': 'Hex Code#RRGGBB', 'lightsalmon': '#FFA07A', 'salmon': '#FA8072', 'darksalmon': '#E9967A', 'lightcoral': '#F08080', 'coral': '#FF7F50', 'tomato': '#FF6347', 'orangered': '#FF4500', 'gold': '#FFD700', 'orange': '#FFA500', 'darkorange': '#FF8C00', 'lightyellow': '#FFFFE0', 'lemonchiffon': '#FFFACD', 'papayawhip': '#FFEFD5', 'moccasin': '#FFE4B5', 'peachpuff': '#FFDAB9', 'palegoldenrod': '#EEE8AA', 'khaki': '#F0E68C', 'darkkhaki': '#BDB76B', 'yellow': '#FFFF00', 'lawngreen': '#7CFC00', 'chartreuse': '#7FFF00', 'limegreen': '#32CD32', 'lime': '#00FF00', 'forestgreen': '#228B22', 'green': '#008000', 'powderblue': '#B0E0E6', 'lightblue': '#ADD8E6', 'lightskyblue': '#87CEFA', 'skyblue': '#87CEEB', 'deepskyblue': '#00BFFF', 'lightsteelblue': '#B0C4DE', 'dodgerblue': '#1E90FF'}\n"
     ]
    }
   ],
   "source": [
    "color_dict = {}\n",
    "for row in table.find_all('tr'): # in html table row is represented by the tag <tr>\n",
    "    # Get all columns in each row.\n",
    "    cols = row.find_all('td') # in html a column is represented by the tag <td>\n",
    "    color_name = cols[2].getText() # store the value in column 3 as color_name\n",
    "    color_code = cols[3].getText() # store the value in column 4 as color_code\n",
    "    color_dict[color_name] = color_code\n",
    "\n",
    "print(color_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.3.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m144.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.3.1-cp312-cp312-manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m184.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.3.1 pandas-2.3.0 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Color Name Hex Code\n",
      "0  lightsalmon  #FFA07A\n",
      "1       salmon  #FA8072\n",
      "2   darksalmon  #E9967A\n",
      "3   lightcoral  #F08080\n",
      "4        coral  #FF7F50\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Remove the descriptive first key\n",
    "color_dict.pop('Color Name', None)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(list(color_dict.items()), columns=['Color Name', 'Hex Code'])\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_item = color_dict.popitem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dodgerblue', '#1E90FF')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(color_dict.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ramesh Sannareddy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Contributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rav Ahuja\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "## Change Log\n",
    "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
    "|---|---|---|---|\n",
    "| 2024-10-29  | 0.2  | Madhusudhan Moole |  Updated lab |\n",
    "| 2020-10-17  | 0.1  | Ramesh Sannareddy  |  Created initial version of the lab |\n",
    "--!>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "47f9ffc1b763f98e682ac3a01d2e9180987012a5e050cb2d84fe1df3c67f42fb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
